{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa793515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dvclive import Live\n",
    "from dvclive.lightning import DVCLiveLogger\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3e6457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, encoder_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Saves any args passed to __init__ (for example, encoder_size)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, encoder_size), nn.ReLU(), nn.Linear(encoder_size, 3))\n",
    "        self.decoder = nn.Sequential(nn.Linear(3, encoder_size), nn.ReLU(), nn.Linear(encoder_size, 28 * 28))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f603c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data\n",
    "dataset = MNIST(os.getcwd(), download=True, transform=ToTensor())\n",
    "train_loader = utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e59fc5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (mps), used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "/Users/dave/miniforge3/envs/torch/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /Users/dave/Code/dvclive-exp-tracking/DvcLiveLogger/dvclive_run/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 50.4 K\n",
      "1 | decoder | Sequential | 51.2 K\n",
      "---------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:01<00:00, 107.11it/s, loss=0.0495, v_num=_run]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:01<00:00, 106.82it/s, loss=0.0495, v_num=_run]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING\u001b[39m: The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\tdvclive-exp-tracking.ipynb, MNIST/raw/t10k-images-idx3-ubyte, MNIST/raw/t10k-labels-idx1-ubyte, MNIST/raw/train-images-idx3-ubyte, MNIST/raw/t10k-images-idx3-ubyte.gz, MNIST/raw/train-images-idx3-ubyte.gz, MNIST/raw/train-labels-idx1-ubyte.gz, MNIST/raw/train-labels-idx1-ubyte, MNIST/raw/t10k-labels-idx1-ubyte.gz, DvcLiveLogger/dvclive_run/checkpoints/epoch=4-step=1000.ckpt, DvcLiveLogger/dvclive_run/checkpoints/epoch=4-step=1000-v1.ckpt, dvclive/metrics.json, dvclive/params.yaml, dvclive/dvc.yaml, dvclive/report.html, dvclive/plots/metrics/epoch.tsv, dvclive/plots/metrics/train_loss.tsv, dvclive/plots/images/numpy.png\n",
      "WARNING:dvc.repo.experiments.save:The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\tdvclive-exp-tracking.ipynb, MNIST/raw/t10k-images-idx3-ubyte, MNIST/raw/t10k-labels-idx1-ubyte, MNIST/raw/train-images-idx3-ubyte, MNIST/raw/t10k-images-idx3-ubyte.gz, MNIST/raw/train-images-idx3-ubyte.gz, MNIST/raw/train-labels-idx1-ubyte.gz, MNIST/raw/train-labels-idx1-ubyte, MNIST/raw/t10k-labels-idx1-ubyte.gz, DvcLiveLogger/dvclive_run/checkpoints/epoch=4-step=1000.ckpt, DvcLiveLogger/dvclive_run/checkpoints/epoch=4-step=1000-v1.ckpt, dvclive/metrics.json, dvclive/params.yaml, dvclive/dvc.yaml, dvclive/report.html, dvclive/plots/metrics/epoch.tsv, dvclive/plots/metrics/train_loss.tsv, dvclive/plots/images/numpy.png\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "live = Live(save_dvc_exp=True)\n",
    "img = np.random.randint(0, 255, (500, 500), np.uint8)\n",
    "live.log_image(\"numpy.png\", img)\n",
    "autoencoder = LitAutoEncoder(encoder_size=64)\n",
    "trainer = pl.Trainer(\n",
    "    limit_train_batches=200,\n",
    "    max_epochs=5,\n",
    "    logger=DVCLiveLogger(experiment=live)\n",
    ")\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef65fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ──────────────────────────────────────────────────────────────────────────────────── \n",
      "  Experiment                 Created        train_loss   epoch   step   encoder_size  \n",
      " ──────────────────────────────────────────────────────────────────────────────────── \n",
      "  workspace                  -                0.059008       4    999   64            \n",
      "  main                       Dec 14, 2022            -       -      -   -             \n",
      "  └── 3350052 [tenty-taco]   02:08 PM         0.059008       4    999   64            \n",
      " ──────────────────────────────────────────────────────────────────────────────────── \n"
     ]
    }
   ],
   "source": [
    "!dvc exp show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f02bfa8ebaa1dae38d977d8c2b7018e9cddf702a1e272af90454e7fd5c68172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
