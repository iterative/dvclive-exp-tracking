{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa793515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dvclive import Live\n",
    "from dvclive.lightning import DVCLiveLogger\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e6457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, encoder_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Saves any args passed to __init__ (for example, encoder_size)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, encoder_size), nn.ReLU(), nn.Linear(encoder_size, 3))\n",
    "        self.decoder = nn.Sequential(nn.Linear(3, encoder_size), nn.ReLU(), nn.Linear(encoder_size, 28 * 28))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data\n",
    "dataset = MNIST(os.getcwd(), download=True, transform=ToTensor())\n",
    "train_loader = utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59fc5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "autoencoder = LitAutoEncoder(encoder_size=128)\n",
    "trainer = pl.Trainer(\n",
    "    limit_train_batches=200,\n",
    "    max_epochs=5,\n",
    "    logger=DVCLiveLogger(save_dvc_exp=True)\n",
    ")\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef65fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dvc.api import exp_show\n",
    "\n",
    "pd.DataFrame(exp_show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98216c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f02bfa8ebaa1dae38d977d8c2b7018e9cddf702a1e272af90454e7fd5c68172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
